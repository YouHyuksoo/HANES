/**
 * @file database/migrate-data.ts
 * @description PostgreSQL â†’ Oracle ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
 *
 * ì‚¬ìš©ë²•:
 * npx ts-node src/database/migrate-data.ts
 */

import { DataSource } from 'typeorm';
import { PrismaClient } from '@prisma/client';
import * as dotenv from 'dotenv';

dotenv.config({ path: '.env.local' });
dotenv.config({ path: '.env' });

// ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
const BATCH_SIZE = 1000;
const CONCURRENCY = 5;

interface MigrationConfig {
  source: DataSource; // PostgreSQL (Prisma)
  target: DataSource; // Oracle (TypeORM)
}

// ë§ˆì´ê·¸ë ˆì´ì…˜í•  í…Œì´ë¸” ëª©ë¡ (ìˆœì„œ ì¤‘ìš” - FK ì˜ì¡´ì„± ê³ ë ¤)
const TABLE_ORDER = [
  // ë§ˆìŠ¤í„° ë°ì´í„° (ì˜ì¡´ì„± ì—†ìŒ)
  'com_codes',
  'company_masters',
  'department_masters',
  'partner_masters',
  'num_rule_masters',
  'plants',
  'prod_line_masters',
  'process_masters',
  'vendor_masters',
  'worker_masters',
  'part_masters',
  'equip_masters',
  'consumable_masters',
  'label_templates',
  'comm_configs',
  
  // BOM (part_masters ì˜ì¡´)
  'bom_masters',
  'process_maps',
  'work_instructions',
  'iqc_item_masters',
  'equip_inspect_item_masters',
  
  // ì‚¬ìš©ì/ê¶Œí•œ
  'users',
  'user_auths',
  
  // ì°½ê³ /LOT
  'warehouses',
  'lots',
  'mat_lots',
  'stocks',
  'mat_stocks',
  
  // êµ¬ë§¤/ì™¸ì£¼
  'purchase_orders',
  'purchase_order_items',
  'subcon_orders',
  'subcon_deliveries',
  'subcon_receives',
  
  // ì‘ì—…ì§€ì‹œ/ìƒì‚°
  'job_orders',
  'prod_results',
  'inspect_results',
  'defect_logs',
  'repair_logs',
  
  // ìì¬/ì¬ê³ 
  'stock_transactions',
  'mat_issues',
  'consumable_logs',
  'inv_adj_logs',
  
  // ì¶œí•˜
  'box_masters',
  'pallet_masters',
  'shipment_logs',
  'shipment_orders',
  'shipment_order_items',
  'shipment_returns',
  'shipment_return_items',
  'customer_orders',
  'customer_order_items',
  
  // ì¶”ì /ì¸í„°í˜ì´ìŠ¤
  'trace_logs',
  'inter_logs',
  
  // ë³´ì„¸
  'customs_entries',
  'customs_lots',
  'customs_usage_reports',
  
  // ì„¤ë¹„ì ê²€
  'equip_inspect_logs',
  'warehouse_transfer_rules',
];

class DataMigrator {
  private prisma: PrismaClient;
  private oracleDataSource: DataSource;
  private stats: Map<string, { source: number; target: number; errors: number }> = new Map();

  constructor() {
    this.prisma = new PrismaClient({
      log: ['warn', 'error'],
    });
  }

  async initialize() {
    console.log('ğŸ”Œ Initializing database connections...\n');

    // Oracle ì—°ê²°
    this.oracleDataSource = new DataSource({
      type: 'oracle',
      host: process.env.ORACLE_HOST || 'localhost',
      port: parseInt(process.env.ORACLE_PORT || '1521', 10),
      username: process.env.ORACLE_USER || 'MES_USER',
      password: process.env.ORACLE_PASSWORD || '',
      sid: process.env.ORACLE_SID || 'ORCL',
      synchronize: false,
      logging: false,
      entities: [],
    });

    await this.oracleDataSource.initialize();
    console.log('âœ… Oracle connection established');

    // PostgreSQL ì—°ê²° í…ŒìŠ¤íŠ¸
    await this.prisma.$connect();
    console.log('âœ… PostgreSQL connection established\n');
  }

  async migrateTable(tableName: string): Promise<void> {
    console.log(`\nğŸ“¦ Migrating table: ${tableName}`);
    console.log('-'.repeat(50));

    const startTime = Date.now();
    let migratedCount = 0;
    let errorCount = 0;

    try {
      // PostgreSQLì—ì„œ ë°ì´í„° ì¡°íšŒ
      const sourceData = await this.prisma.$queryRawUnsafe(`
        SELECT * FROM "${tableName}" 
        WHERE "deleted_at" IS NULL 
        ORDER BY "created_at" ASC
      `);

      const sourceRows = sourceData as any[];
      console.log(`   Source records: ${sourceRows.length}`);

      if (sourceRows.length === 0) {
        console.log(`   â­ï¸  Skipping (no data)`);
        this.stats.set(tableName, { source: 0, target: 0, errors: 0 });
        return;
      }

      // ì»¬ëŸ¼ëª… ë§¤í•‘ (snake_case â†’ UPPER_CASE)
      const mappedRows = sourceRows.map((row) => this.mapColumns(row));

      // ë°°ì¹˜ ì²˜ë¦¬
      for (let i = 0; i < mappedRows.length; i += BATCH_SIZE) {
        const batch = mappedRows.slice(i, i + BATCH_SIZE);
        
        try {
          await this.insertBatch(tableName, batch);
          migratedCount += batch.length;
          process.stdout.write(`   Progress: ${migratedCount}/${sourceRows.length}\r`);
        } catch (error: any) {
          console.error(`\n   âŒ Batch error: ${error.message}`);
          errorCount += batch.length;
          
          // ê°œë³„ í–‰ ì¬ì‹œë„
          for (const row of batch) {
            try {
              await this.insertBatch(tableName, [row]);
              migratedCount++;
              errorCount--;
            } catch (innerError) {
              // ê°œë³„ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì†
            }
          }
        }
      }

      const duration = ((Date.now() - startTime) / 1000).toFixed(2);
      console.log(`\n   âœ… Completed: ${migratedCount} rows in ${duration}s`);
      
      this.stats.set(tableName, {
        source: sourceRows.length,
        target: migratedCount,
        errors: errorCount,
      });

    } catch (error: any) {
      console.error(`   âŒ Migration failed: ${error.message}`);
      this.stats.set(tableName, { source: 0, target: 0, errors: 1 });
    }
  }

  private mapColumns(row: any): any {
    const mapped: any = {};
    
    for (const [key, value] of Object.entries(row)) {
      // snake_case â†’ UPPER_CASE ë³€í™˜
      const upperKey = key.toUpperCase();
      
      // ê°’ ë³€í™˜
      if (value instanceof Date) {
        mapped[upperKey] = value;
      } else if (typeof value === 'object' && value !== null) {
        // JSON â†’ ë¬¸ìì—´ (CLOB)
        mapped[upperKey] = JSON.stringify(value);
      } else {
        mapped[upperKey] = value;
      }
    }
    
    return mapped;
  }

  private async insertBatch(tableName: string, rows: any[]): Promise<void> {
    if (rows.length === 0) return;

    const upperTableName = tableName.toUpperCase();
    const columns = Object.keys(rows[0]);
    
    // ë™ì  INSERT ì¿¼ë¦¬ ìƒì„±
    const placeholders = columns.map((_, i) => `:${i + 1}`).join(', ');
    const sql = `INSERT INTO ${upperTableName} (${columns.join(', ')}) VALUES (${placeholders})`;

    // ë°°ì¹˜ ì‹¤í–‰
    for (const row of rows) {
      const values = columns.map((col) => row[col]);
      await this.oracleDataSource.query(sql, values);
    }
  }

  async migrateAll(): Promise<void> {
    console.log('\nğŸš€ Starting data migration...\n');
    console.log('=' .repeat(60));

    const totalStartTime = Date.now();

    for (const tableName of TABLE_ORDER) {
      await this.migrateTable(tableName);
    }

    const totalDuration = ((Date.now() - totalStartTime) / 1000).toFixed(2);

    // í†µê³„ ì¶œë ¥
    this.printStats(totalDuration);
  }

  private printStats(duration: string): void {
    console.log('\n\n' + '='.repeat(60));
    console.log('ğŸ“Š Migration Statistics');
    console.log('='.repeat(60));
    console.log(`\nTotal Duration: ${duration}s\n`);
    
    console.log('Table Name                 | Source | Target | Errors | Status');
    console.log('-'.repeat(70));
    
    let totalSource = 0;
    let totalTarget = 0;
    let totalErrors = 0;

    for (const [tableName, stat] of this.stats) {
      totalSource += stat.source;
      totalTarget += stat.target;
      totalErrors += stat.errors;
      
      const status = stat.errors === 0 && stat.source === stat.target ? 'âœ…' : 
                    stat.errors > 0 ? 'âš ï¸' : 'â­ï¸';
      
      console.log(
        `${tableName.padEnd(26)} | ${String(stat.source).padStart(6)} | ${String(stat.target).padStart(6)} | ${String(stat.errors).padStart(6)} | ${status}`
      );
    }
    
    console.log('-'.repeat(70));
    console.log(
      `${'TOTAL'.padEnd(26)} | ${String(totalSource).padStart(6)} | ${String(totalTarget).padStart(6)} | ${String(totalErrors).padStart(6)} |`
    );
    console.log('\n' + '='.repeat(60));
    console.log(totalErrors === 0 ? 'âœ… Migration completed successfully!' : `âš ï¸ Migration completed with ${totalErrors} errors`);
    console.log('='.repeat(60) + '\n');
  }

  async close(): Promise<void> {
    await this.prisma.$disconnect();
    if (this.oracleDataSource.isInitialized) {
      await this.oracleDataSource.destroy();
    }
    console.log('ğŸ”Œ Connections closed');
  }
}

// ë©”ì¸ ì‹¤í–‰
async function main() {
  const migrator = new DataMigrator();

  try {
    await migrator.initialize();
    await migrator.migrateAll();
  } catch (error: any) {
    console.error('\nâŒ Migration failed:', error.message);
    process.exit(1);
  } finally {
    await migrator.close();
  }
}

// ì§ì ‘ ì‹¤í–‰
if (require.main === module) {
  main();
}

export { DataMigrator };
